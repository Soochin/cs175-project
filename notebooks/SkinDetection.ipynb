{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkinDetection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soochin/cs175-project/blob/master/notebooks/SkinDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "FZMV-ETlHc-c",
        "colab_type": "code",
        "outputId": "233add80-87fe-4c7b-9adf-5d3e84010167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My\\ Drive/School/Year\\ 4/Winter/CS\\ 175/Final Project/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/School/Year 4/Winter/CS 175/Final Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T4XthQnNQa2P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import io\n",
        "import os\n",
        "import timeit\n",
        "from PIL import Image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sos28uPgGikw",
        "colab_type": "code",
        "outputId": "3ddebe1e-e15c-422c-e5f4-1b2c76f123ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "#Create giant tensor files from hand images\n",
        "#ONLY DO IF THE .pt FILES HAVE NOT YET BEEN CREATED\n",
        "transform = T.ToTensor()\n",
        "i=0\n",
        "ts = []\n",
        "outputBatch =0 \n",
        "for handFile in os.listdir('./data/skin_detection_data/skin_detected_hands_128'):\n",
        "  t = transform(Image.open('./data/skin_detection_data/skin_detected_hands_128/'+handFile))\n",
        "  ts.append(t)\n",
        "  i += 1\n",
        "  if i%50 == 0:\n",
        "    print(i, end=',')\n",
        "  if i%1000 == 0:\n",
        "    print()\n",
        "    t_stacked = torch.stack(ts)\n",
        "    ts = []\n",
        "    print(t_stacked.size())\n",
        "    torch.save(t_stacked, './data/skin_detection_data/hands/batch_'+str(outputBatch)+'.pt')\n",
        "    outputBatch += 1\n",
        "    t_stacked = None\n",
        "t_stacked = torch.stack(ts)\n",
        "ts = []\n",
        "print(t_stacked.size())\n",
        "torch.save(t_stacked, './data/skin_detection_data/hands/batch_'+str(outputBatch)+'.pt')\n",
        "t_stacked = None\n",
        "\n",
        "#Clean out memory\n",
        "ts = []\n",
        "t_stacked = None\n",
        "i = 0\n",
        "t = None"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "1050,1100,1150,1200,1250,1300,1350,1400,1450,1500,1550,1600,1650,1700,1750,1800,1850,1900,1950,2000,\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "2050,2100,2150,2200,2250,2300,2350,2400,2450,2500,2550,2600,2650,2700,2750,2800,2850,2900,2950,3000,\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "3050,3100,3150,3200,3250,3300,3350,3400,3450,torch.Size([498, 3, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1oBnNW9iv_FL",
        "colab_type": "code",
        "outputId": "a80d0bd9-ed69-4cc8-d5bc-95f608c2f80f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "#Create giant tensor files from nohand images\n",
        "#ONLY DO IF THE .pt FILES HAVE NOT YET BEEN CREATED\n",
        "transform = T.ToTensor()\n",
        "i=0\n",
        "ts = []\n",
        "outputBatch =0 \n",
        "for handFile in os.listdir('./data/skin_detection_data/skin_detected_nohands_128'):\n",
        "  t = transform(Image.open('./data/skin_detection_data/skin_detected_nohands_128/'+handFile))\n",
        "  ts.append(t)\n",
        "  i += 1\n",
        "  if i%50 == 0:\n",
        "    print(i, end=',')\n",
        "  if i%1000 == 0:\n",
        "    print()\n",
        "    t_stacked = torch.stack(ts)\n",
        "    ts = []\n",
        "    print(t_stacked.size())\n",
        "    torch.save(t_stacked, './data/skin_detection_data/nohands/batch_'+str(outputBatch)+'.pt')\n",
        "    outputBatch += 1\n",
        "    t_stacked = None\n",
        "t_stacked = torch.stack(ts)\n",
        "ts = []\n",
        "print(t_stacked.size())\n",
        "torch.save(t_stacked, './data/skin_detection_data/nohands/batch_'+str(outputBatch)+'.pt')\n",
        "t_stacked = None\n",
        "\n",
        "#Clean out memory\n",
        "ts = []\n",
        "t_stacked = None\n",
        "i = 0\n",
        "t = None"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "1050,1100,1150,1200,1250,1300,1350,1400,1450,1500,1550,1600,1650,1700,1750,1800,1850,1900,1950,2000,\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "2050,2100,2150,2200,2250,2300,2350,2400,2450,2500,2550,2600,2650,2700,2750,2800,2850,2900,2950,3000,\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "3050,3100,3150,3200,3250,3300,3350,3400,3450,3500,3550,3600,3650,3700,3750,3800,3850,3900,3950,4000,\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "4050,4100,4150,4200,torch.Size([220, 3, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e-8L0QOVHUZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class HandClassifyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, rootdir):\n",
        "    self.rootdir = rootdir\n",
        "    self.handsdir = self.rootdir+'hands/'\n",
        "    self.nohandsdir = self.rootdir+'nohands/'\n",
        "    self.handIms = []\n",
        "    self.nohandIms = []\n",
        "    i = 0\n",
        "    for batch in os.listdir(self.handsdir):\n",
        "      if \"batch\" in batch:\n",
        "        t = torch.load(self.handsdir+batch)\n",
        "        print(t.size())\n",
        "        self.handIms.append(t)\n",
        "        print('Batch done')\n",
        "    self.handIms = torch.cat(self.handIms, 0)\n",
        "    print(self.handIms.size())\n",
        "    for batch in os.listdir(self.nohandsdir):\n",
        "      if \"batch\" in batch:\n",
        "        t = torch.load(self.nohandsdir+batch)\n",
        "        print(t.size())\n",
        "        self.nohandIms.append(t)\n",
        "        print('Batch done')\n",
        "    self.nohandIms = torch.cat(self.nohandIms, 0)\n",
        "    print(self.nohandIms.size())\n",
        "    self.ind = [x for x in range(self.handIms.size()[0]+ self.nohandIms.size()[0])]\n",
        "    random.shuffle(self.ind)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.handIms.size()[0]+self.nohandIms.size()[0]\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    idx = self.ind[idx]\n",
        "    if idx < self.handIms.size()[0]:\n",
        "      sample = (self.handIms[idx,:,:,:], 1)\n",
        "      return sample\n",
        "    elif idx < self.handIms.size()[0] + self.nohandIms.size()[0]:\n",
        "      idx = idx-self.handIms.size()[0]\n",
        "      sample = (self.nohandIms[idx,:,:,:], 0)\n",
        "      #print(handBoxes[handFiles[idx]].size())\n",
        "      return sample\n",
        "    else:\n",
        "      raise IndexError"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OvX3ThXQVFQF",
        "colab_type": "code",
        "outputId": "0e23d14a-94cf-4651-8d61-743b5f8bad79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "cell_type": "code",
      "source": [
        "hands_dataset = None\n",
        "hands_dataset = HandClassifyDataset(rootdir='./data/skin_detection_data/')\n",
        "print(len(hands_dataset))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1000, 3, 128, 128])\n",
            "Batch done\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "Batch done\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "Batch done\n",
            "torch.Size([498, 3, 128, 128])\n",
            "Batch done\n",
            "torch.Size([3498, 3, 128, 128])\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "Batch done\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "Batch done\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "Batch done\n",
            "torch.Size([1000, 3, 128, 128])\n",
            "Batch done\n",
            "torch.Size([220, 3, 128, 128])\n",
            "Batch done\n",
            "torch.Size([4220, 3, 128, 128])\n",
            "7718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g7JyGzLXFxuV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ChunkSampler(sampler.Sampler):\n",
        "    \"\"\"Samples elements sequentially from some offset. \n",
        "    Arguments:\n",
        "        num_samples: # of desired datapoints\n",
        "        start: offset where we should start selecting from\n",
        "    \"\"\"\n",
        "    def __init__(self, num_samples, start = 0):\n",
        "        self.num_samples = num_samples\n",
        "        self.start = start\n",
        "\n",
        "    def __iter__(self):\n",
        "        return iter(range(self.start, self.start + self.num_samples))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "hands_dataset_size = len(hands_dataset)\n",
        "NUM_VAL = int(np.ceil(0.12*hands_dataset_size))\n",
        "NUM_TEST = int(np.ceil(0.13*hands_dataset_size))\n",
        "NUM_TRAIN = len(hands_dataset)-NUM_VAL-NUM_TEST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9R7KzYBYF35M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(hands_dataset, batch_size=64, num_workers=4, sampler=ChunkSampler(NUM_TRAIN, 0))\n",
        "val_loader = torch.utils.data.DataLoader(hands_dataset, batch_size=64, num_workers=4, sampler=ChunkSampler(NUM_VAL, NUM_TRAIN))\n",
        "test_loader = torch.utils.data.DataLoader(hands_dataset, batch_size=64, num_workers=4, sampler=ChunkSampler(NUM_TEST, NUM_TRAIN+NUM_VAL))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K_ZHUJM9N_xe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import copy\n",
        "gpu_dtype = torch.cuda.FloatTensor\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "def train(model, loss_fn, optimizer, num_epochs = 1):\n",
        "  train_acc = list()\n",
        "  val_acc = list()\n",
        "  models = list()\n",
        "\n",
        "  loss_tr = 0\n",
        "\n",
        "  total_step = len(train_loader)\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      #Forward pass\n",
        "      outputs = model(images)\n",
        "      loss_tr = loss_fn(outputs, labels)\n",
        "\n",
        "      #Backward and optimize\n",
        "      optimizer.zero_grad()\n",
        "      loss_tr.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      if (i+1)%30 == 0:\n",
        "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "             .format(epoch+1, num_epochs, i+1, total_step, loss_tr.item()))\n",
        "    acc = check_accuracy(model, val_loader)\n",
        "    train_acc.append(loss_tr.item())\n",
        "    val_acc.append(acc)\n",
        "    models.append(model)\n",
        "  best = val_acc.index(max(val_acc))\n",
        "  print('Best Model: Train Accuracy {}, Test Accuracy {}'.format(train_acc[best]*100, val_acc[best]*100))\n",
        "  return models[best]\n",
        "\n",
        "def check_accuracy(model, loader):   \n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval() # Put the model in test mode (the opposite of model.train(), essentially)\n",
        "    for x, y in loader:\n",
        "        x_var = Variable(x.type(gpu_dtype), volatile=True)\n",
        "\n",
        "        scores = model(x_var)\n",
        "        _, preds = scores.data.cpu().max(1)\n",
        "        num_correct += (preds == y).sum()\n",
        "        num_samples += preds.size(0)\n",
        "    acc = float(num_correct) / num_samples\n",
        "    print('Test Accuracy of the model: Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
        "    return acc\n",
        "\n",
        "# Constant to control how frequently we print train loss\n",
        "print_every = 10\n",
        "\n",
        "# This is a little utility that we'll use to reset the model\n",
        "# if we want to re-initialize all our parameters\n",
        "def reset(m):\n",
        "    if hasattr(m, 'reset_parameters'):\n",
        "        m.reset_parameters()\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.size() # read in N, C, H, W\n",
        "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZIocSzF4P0jl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "e4a3750d-8cdb-4e5a-8754-1b908cc8f2e3"
      },
      "cell_type": "code",
      "source": [
        "#Simple model to test if DataLoader works\n",
        "simple_model = nn.Sequential(\n",
        "                nn.Conv2d(3, 128, kernel_size=7, stride=2),\n",
        "                nn.ReLU(inplace=True),\n",
        "                Flatten(), # see above for explanation\n",
        "                nn.Linear(476288, 2), # affine layer\n",
        "              )\n",
        "# Set the type of all data in this model to be FloatTensor \n",
        "simple_model.type(gpu_dtype)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "optimizer = optim.Adam(simple_model.parameters(), lr=1e-2) # lr sets the learning rate of the optimizer\n",
        "\n",
        "simple_model.apply(reset)\n",
        "train(simple_model, loss_fn, optimizer, num_epochs=1)\n",
        "check_accuracy(simple_model, val_loader)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/1], Step [30/91], Loss: 0.6636\n",
            "Epoch [1/1], Step [60/91], Loss: 0.6951\n",
            "Epoch [1/1], Step [90/91], Loss: 0.6913\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model: Got 474 / 927 correct (51.13)\n",
            "Best Model: Train Accuracy 69.94981169700623, Test Accuracy 51.1326860841424\n",
            "Test Accuracy of the model: Got 474 / 927 correct (51.13)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.511326860841424"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "f-r6mZd7RPMM",
        "colab_type": "code",
        "outputId": "f77b4926-a96e-48d5-c04c-9d5f6a940029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        }
      },
      "cell_type": "code",
      "source": [
        "#Same model as used in general convolutional base model (control)\n",
        "\n",
        "learning_rate = 1e-3\n",
        "\n",
        "class GenConvNet(nn.Module):\n",
        "  def __init__(self, num_classes=2):\n",
        "    super(GenConvNet, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "      nn.BatchNorm2d(16),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "      nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc = nn.Linear(32768, num_classes)\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.reshape(out.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "  \n",
        "controlModel = GenConvNet().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "optimizer = torch.optim.Adam(controlModel.parameters(), lr=learning_rate)\n",
        "\n",
        "best_model = train(controlModel, loss_fn, optimizer, num_epochs=10)\n",
        "check_accuracy(best_model, test_loader)\n",
        "\n",
        "#Using the optimized parameters for the regular images we struggle to break 65% accuracy"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [30/91], Loss: 0.7758\n",
            "Epoch [1/10], Step [60/91], Loss: 0.8459\n",
            "Epoch [1/10], Step [90/91], Loss: 0.7281\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model: Got 474 / 927 correct (51.13)\n",
            "Epoch [2/10], Step [30/91], Loss: 0.7240\n",
            "Epoch [2/10], Step [60/91], Loss: 0.8426\n",
            "Epoch [2/10], Step [90/91], Loss: 0.6348\n",
            "Test Accuracy of the model: Got 536 / 927 correct (57.82)\n",
            "Epoch [3/10], Step [30/91], Loss: 0.6554\n",
            "Epoch [3/10], Step [60/91], Loss: 0.8175\n",
            "Epoch [3/10], Step [90/91], Loss: 0.5866\n",
            "Test Accuracy of the model: Got 469 / 927 correct (50.59)\n",
            "Epoch [4/10], Step [30/91], Loss: 0.5884\n",
            "Epoch [4/10], Step [60/91], Loss: 0.6151\n",
            "Epoch [4/10], Step [90/91], Loss: 0.5576\n",
            "Test Accuracy of the model: Got 552 / 927 correct (59.55)\n",
            "Epoch [5/10], Step [30/91], Loss: 0.5909\n",
            "Epoch [5/10], Step [60/91], Loss: 0.7317\n",
            "Epoch [5/10], Step [90/91], Loss: 0.4948\n",
            "Test Accuracy of the model: Got 566 / 927 correct (61.06)\n",
            "Epoch [6/10], Step [30/91], Loss: 0.5118\n",
            "Epoch [6/10], Step [60/91], Loss: 0.6090\n",
            "Epoch [6/10], Step [90/91], Loss: 0.4362\n",
            "Test Accuracy of the model: Got 605 / 927 correct (65.26)\n",
            "Epoch [7/10], Step [30/91], Loss: 0.6021\n",
            "Epoch [7/10], Step [60/91], Loss: 0.6472\n",
            "Epoch [7/10], Step [90/91], Loss: 0.4107\n",
            "Test Accuracy of the model: Got 608 / 927 correct (65.59)\n",
            "Epoch [8/10], Step [30/91], Loss: 0.4729\n",
            "Epoch [8/10], Step [60/91], Loss: 0.4951\n",
            "Epoch [8/10], Step [90/91], Loss: 0.3474\n",
            "Test Accuracy of the model: Got 603 / 927 correct (65.05)\n",
            "Epoch [9/10], Step [30/91], Loss: 0.4439\n",
            "Epoch [9/10], Step [60/91], Loss: 0.4660\n",
            "Epoch [9/10], Step [90/91], Loss: 0.3521\n",
            "Test Accuracy of the model: Got 562 / 927 correct (60.63)\n",
            "Epoch [10/10], Step [30/91], Loss: 0.4262\n",
            "Epoch [10/10], Step [60/91], Loss: 0.5993\n",
            "Epoch [10/10], Step [90/91], Loss: 0.3664\n",
            "Test Accuracy of the model: Got 545 / 927 correct (58.79)\n",
            "Best Model: Train Accuracy 42.98064410686493, Test Accuracy 65.58791801510249\n",
            "Test Accuracy of the model: Got 552 / 1004 correct (54.98)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.549800796812749"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "metadata": {
        "id": "kUnHlcrG7CFR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "83d253e1-3956-4d1b-b67f-0561996aed98"
      },
      "cell_type": "code",
      "source": [
        "#Specialized Model for Preprocessed Images\n",
        "\n",
        "learning_rate = 1e-3\n",
        "\n",
        "class SkinConvNet(nn.Module):\n",
        "  def __init__(self, num_classes=2):\n",
        "    super(SkinConvNet, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "      nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
        "      nn.BatchNorm2d(16),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "      nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "      nn.BatchNorm2d(32),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "      nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.fc = nn.Linear(16384, num_classes)\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = out.reshape(out.size(0), -1)\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "  \n",
        "skinModel = SkinConvNet().to(device)\n",
        "loss_fn = nn.CrossEntropyLoss().type(gpu_dtype)\n",
        "optimizer = torch.optim.Adam(skinModel.parameters(), lr=learning_rate)\n",
        "\n",
        "best_model = train(skinModel, loss_fn, optimizer, num_epochs=5)\n",
        "check_accuracy(best_model, test_loader)\n",
        "\n",
        "#Using the optimized parameters for the regular images we struggle to break 65% accuracy"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [30/91], Loss: 0.7815\n",
            "Epoch [1/5], Step [60/91], Loss: 0.8032\n",
            "Epoch [1/5], Step [90/91], Loss: 0.7019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:43: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model: Got 509 / 927 correct (54.91)\n",
            "Epoch [2/5], Step [30/91], Loss: 0.6892\n",
            "Epoch [2/5], Step [60/91], Loss: 0.7944\n",
            "Epoch [2/5], Step [90/91], Loss: 0.6146\n",
            "Test Accuracy of the model: Got 590 / 927 correct (63.65)\n",
            "Epoch [3/5], Step [30/91], Loss: 0.7634\n",
            "Epoch [3/5], Step [60/91], Loss: 0.7204\n",
            "Epoch [3/5], Step [90/91], Loss: 0.5630\n",
            "Test Accuracy of the model: Got 609 / 927 correct (65.70)\n",
            "Epoch [4/5], Step [30/91], Loss: 0.7603\n",
            "Epoch [4/5], Step [60/91], Loss: 0.6722\n",
            "Epoch [4/5], Step [90/91], Loss: 0.5134\n",
            "Test Accuracy of the model: Got 521 / 927 correct (56.20)\n",
            "Epoch [5/5], Step [30/91], Loss: 0.6177\n",
            "Epoch [5/5], Step [60/91], Loss: 0.6376\n",
            "Epoch [5/5], Step [90/91], Loss: 0.4939\n",
            "Test Accuracy of the model: Got 603 / 927 correct (65.05)\n",
            "Best Model: Train Accuracy 68.70242953300476, Test Accuracy 65.69579288025889\n",
            "Test Accuracy of the model: Got 687 / 1004 correct (68.43)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6842629482071713"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}